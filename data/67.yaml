#
# 67.yaml | Honeycomb
# https://www.honeycomb.io/blog/bitten-by-a-kafka-bug-postmortem
# 
# 
#
# Researcher Notes:
#

IR-67:

  extractedBy: Matt
  reviewedBy:

  ######################################
  # Meta
  ######################################

  patterns:
    # - Towards Automation:
    #   - AI-5 is about automatic recovery from similar failures

    - Responder options / Tools and information for responders:
      - AI-2 adds monitoring
      - AI-3 gives important mapping data to Responders
      - AI-4 adds monitoring

    - Responder options / Improve recovery:
      - AI-5 add automation (where reasonable)
      - AI-6 human runbook (for rest)

  memos:
    # The type of outage we experienced was a new one for this team. But it was also a particularly constructive outage, because it helped several members of team level up substantially on their kafka knowledge and their mental model of how to recover from any operationally degraded kafka scenario.
    - LFI
    - What good came out of incident, towards preventing the next one.

    # In some ways this was inevitable, and it’s a relief that it happened sooner rather than later.
    - Mindsets for incidents
    - Better to happen sooner rather than later

  ######################################
  # AIs
  ######################################

  AI-1: 
    # This is apparently all due to a number of issues that have been fixed by kafka 0.10.2.1, so we need to upgrade our cluster ASAP

    motivation:
      experience: Zookeeper cluster experienced a network partition and the controller did something about it to make it symptomatic much later
      lifecycle:
        - Failure / Inception
      tags:
        - infrastructure disruption (network partition and following outage by controller behavior)
      iso:
        - Faultlessness

    item:
      action: Upgrade cluster
      target: Cluster infrastructure (Kafka)
      goal: Remove triggering and contributing factors that have already been fixed

      action-type:
        - evo / alter # upgrade
      target-type:
        - Fleets / Management systems
      sts:
        - Tech / Core
      intended-effect:
        - Reliability / Faultlessness
      temporal: new
      google-ai:
        - prevent

    other:
      modification: Fix defects in third party developed dependency

    memos:
      - Priority is ASAP, since the triggering is fixed already, but they haven't updated to it yet

  AI-2:
    # Get better instrumentation for kafka and zookeeper into honeycomb

    motivation:
      experience: UNCLEAR # Could have been anything, though potentially the fact that they went down several wrong debugging paths

    item:
      action: Increase monitoring and instrumentation
      target: Monitoring for kafka and zookeeper systems
      goal: Improve diagnosis and debugging

      action-type:
        - evo / add
      target-type:
        - Monitoring and metrics
      sts:
        - Tech / Support
      intended-effect:
        - Maintainability / Analysability
      temporal: new
      google-ai:
        - mitigate future


  AI-3:
    # Get the retriever kafka partition into ec2 instance tags, write shell functions for printing retriever/partition mappings

    motivation:
      experience: UNCLEAR

    item:
      action: Add extra metadata to running instances (retriever/partition mappings)
      target: Kafka retrievers & debugging scripts
      goal: Reduce confusion and cognitive load during debugging and monitoring

      action-type:
        - evo / alter
      target-type:
        - Incident response tools and process / Diagnosis
      sts:
        - Tech / Core
      intended-effect:
        - Maintainability / Analysability
      temporal: new
      google-ai:
        - mitigate future

  
  AI-4:
    # [Responders had to check kafka output to see failures had occurred] Instrumentation for failed writes to kafka (consume sarama response queue?)

    motivation:
      experience: Responder efforts delayed by having to check outputs to see if failures were present
      lifecycle:
        - Response / Detection
        - Response / Triage
      tags:
        - delayed RCA (had to check to see if there was an issue first)
        - missing monitoring (instrumentation)
      iso:
        - Recoverability

    item:
      action: Add monitoring for failed writes
      target: Kafka client (sarama) response queue (internal channels in Go)
      goal: Improve detection of failures (UNCLEAR)

      action-type:
        - evo / alter
      target-type:
        - General services
      sts:
        - Tech / Core 
      intended-effect:
        - Maintainability / Analysability
      temporal: new
      google-ai:
        - detect

  AI-5:
    # After restarting all kafka nodes (which we did with perhaps too much caution and care… it was a first time for the engineers working the outage), it turned out that the data nodes had an offset far ahead of the acknowledged offset, because kafka had kept accepting writes even though zookeeper didn’t acknowledge them as being part of the world.So we had to manually reset the offset on the data nodes and restart or bootstrap them as well. By 12:03pm the world was restored to order. [So we will...] Change the way data nodes handle invariants, to avoid manual intervention when it has with a kafka offset ahead of the broker’s

    motivation:
      experience: Kafka was accepting writes even though zookeeper didn't acknowledge them, requiring that engineers had to manual reset the offset and restart/bootstrap them
      lifecycle:
        - Response / Mitigation
      tags:
        - manual action required (reset offset for data consumption)
      iso:
        - Recoverability

    item:
      action: Change offset handling
      target: Kafka nodes (offset invariants) # from chatgpt: For example, a data node might have an invariant that its recorded Kafka offset should never exceed the broker’s current offset
      goal: Allow automated recovery when coming online to discrepancies in kafka offset

      action-type:
        - evo / alter
      target-type:
        - General services
      sts:
        - Tech / Core
      intended-effect:
        - Reliability / Recoverability
      temporal: new
      google-ai:
        - mitigate future

    themes:
      - automation / eliminate manual recovery steps (kafka offsets)

  
  AI-6:
    # Document the bash snippets, command lines, and other bits we used to debug retriever and kafka and create a production runbook for them

    motivation:
      experience: Response involved a lot of custom tools to triage and debug
      lifecycle:
        - Response / Diagnosis
      tags:
        - manual action required (building tools, mitigating effects)
        - human factors (learning during the incident)
        - custom tools required
      iso:
        - Recoverability

    item:
      action: Document and create a production runbook for recovery processes
      target: Runbook for debugging retrievers and Kafka
      goal: Formalize important parts of recovery processes

      action-type:
        - evo / add
      target-type:
        - Incident response tools and process / Diagnosis
      sts:
        - Process / Recovery 
      intended-effect:
        - Reliability / Recoverability
      temporal: new
      google-ai:
        - mitigate future

    memos:
      - This mitigates also defects which can be introduced in the future